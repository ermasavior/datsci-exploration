{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means From The Scratch\n",
    "In this hands-on, we will implement clustering method, K-Means, from the scratch. The dataset used in this hands-on is MNIST DIGIT, thas is already provided in the zip file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the Dataset\n",
    "\n",
    "Execute the following code to read the digit mnist dataset. The folder of `digit_mnist` dataset must be in the same directory with this python file.\n",
    "\n",
    "The dataset contains 500 digit handwritten images from 5 different classes/labels (0, 1, 2, 3, 4). The first 100 images have label of 0, the second 100 images have label of 1, and so on, until the fifth 100 images have label of 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (500, 784)\n"
     ]
    }
   ],
   "source": [
    "# membaca library yang dibutuhkan\n",
    "import numpy as np #library untuk komputasi matriks\n",
    "import cv2 #library untuk memproses gambar/video\n",
    "import matplotlib.pyplot as plt #library untuk plot data (visualisasi)\n",
    "import os\n",
    "\n",
    "# fungsi untuk membaca gambar (digit MNIST) ke matriks numpy per folder\n",
    "def baca_image(folder_image):\n",
    "    count = 0;\n",
    "    list_nama_image= os.listdir(folder_image)\n",
    "    list_path_image = [os.path.join(folder_image, i) for i in list_nama_image]\n",
    "    all_image = np.ndarray(shape=(0,28*28))\n",
    "    for i in list_path_image:\n",
    "        image = cv2.imread(i, 0) #baca image menggunakan OpenCV API dalam gray image (0=gray, 1=berwarna).\n",
    "        image_reshaped = image.reshape((1, -1))\n",
    "        all_image = np.concatenate((all_image, image_reshaped), axis=0)\n",
    "        count = count + 1\n",
    "        if count >= 100:\n",
    "            break\n",
    "    return all_image\n",
    "        \n",
    "# menggunakan fungsi yg telah dibuat untuk membaca image MNIST '0' sampai '4' \n",
    "for angka in range(5):\n",
    "    file = \"digit_mnist/\" + str(angka)\n",
    "    digit = baca_image(file)\n",
    "    if angka == 0:\n",
    "        X = digit\n",
    "    else :\n",
    "        X = np.concatenate((X, digit), axis=0)\n",
    "\n",
    "print(\"shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Create K-Means Function\n",
    "In this block below, you have been provided a function template where you can implement K-Means algorithm for clustering. You need to complete `def kmeans(X, group)` function with the input are: (i) `input_dataset` (the data that you want to cluster), and (ii) `number_of_groups` (where you can define how many clustering groups that you want to create). The output of this function is **a 1D-array of cluster label for each instance in the dataset**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 1, 0, 0, 0, 4, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 2, 3, 3, 3, 2, 3, 3, 2, 3, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 2, 3, 2, 3, 2, 2, 2, 3, 3, 3, 2, 2, 3, 2, 3, 2, 3, 2, 2, 3, 3, 3, 2, 2, 2, 3, 3, 3, 3, 2, 3, 2, 2, 3, 2, 3, 3, 3, 3, 2, 2, 3, 3, 3, 2, 2, 2, 3, 3, 2, 3, 3, 3, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 2, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 4, 1, 3, 2, 1, 1, 4, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 4, 4, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 4, 1, 4, 1, 1, 1, 1, 1, 4, 1, 4, 2, 1, 2, 4, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 1, 2, 4, 4, 1, 2, 1, 2, 1, 2, 2, 2, 2, 2, 4, 1, 4, 1, 1, 1, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 1, 2, 1, 1, 3, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2, 1, 4, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 1, 2, 3, 2, 2, 4, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 2, 4, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from scipy.spatial import distance\n",
    "\n",
    "def kmeans(input_dataset, number_of_groups = 5):\n",
    "    '''\n",
    "    parameter :\n",
    "        input_dataset = the input dataset that you want to cluster\n",
    "        number_of_groups = how many cluster you want to create\n",
    "                           in this case is 5.\n",
    "        \n",
    "    return :\n",
    "        array of cluster labels for each instances in dataset\n",
    "    \n",
    "    '''\n",
    "    size = len(input_dataset)\n",
    "    centroids = random.sample(list(input_dataset), number_of_groups)\n",
    "    centroids = np.array(centroids)\n",
    "\n",
    "    count = 0\n",
    "    while True:\n",
    "        count += 1\n",
    "        Y = []\n",
    "        clusters = [[] for i in range(number_of_groups)]\n",
    "        for data in input_dataset:\n",
    "            label = clusterize_data(data, centroids)\n",
    "            clusters[label].append(data)\n",
    "            Y.append(label)\n",
    "\n",
    "        new_centroids = []\n",
    "        for cluster in clusters:\n",
    "            new_centroids.append(np.mean(cluster, axis = 0))\n",
    "        new_centroids = np.array(new_centroids)\n",
    "\n",
    "        if (new_centroids == centroids).all():\n",
    "            break\n",
    "        else:\n",
    "            centroids = new_centroids\n",
    "\n",
    "    return Y\n",
    "\n",
    "def clusterize_data(data, centroids):\n",
    "    distances = []\n",
    "    for centroid in centroids:\n",
    "        dist = distance.euclidean(data, centroid)\n",
    "        distances.append(dist)\n",
    "    return np.argmin(distances)\n",
    "\n",
    "number_of_groups = 5\n",
    "kmeans_result = kmeans(X, number_of_groups)\n",
    "print(kmeans_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Evaluate Cluster Model\n",
    "Note that in reality, actually, we don't have clustering label ground truth. But for pedagogical purpose, we use MNIST datataset that we already know the label (ground truth), and we will evaluate our clustering result with those ground truth label. To do this, execute function that you've create in the previous question with parameter inputs of `X` (digit mnist) as `input_dataset` and 5 as `number_of_groups`. Then, report specifications below.\n",
    "\n",
    "**Q2.a.** For each cluster (of 5 clusters), show the composition of the cluster members, e.g., `Cluster 1 -> digit 0: 78, digit 1: 3, digit 2: 7, digit 3: 5, digit 4: 1`, and so on until `Cluster 5`.<br><br> \n",
    "**Q2.b.** Since we know the ground truth label of the MNSIT dataset, thus, `cluster label prediction` is the one dominating that cluster. For instance in example of Q2.a above, `cluster label prediction` of `Cluster 1` is `digit 0`, since `digit 0` dominates that cluster with 78 images. By having this in mind, we can think each cluster is just like a \"binary classification\" of \"one vs rest\". In example `Cluster 1` above, it will be a binary classification of \"digit 0 vs not digit 0\". Your task is: for each cluster, print `recall` (true positive / actual posive) and `specificity` (true negative / actual negative). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q02.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 1 -> digit 0: 89  digit 1: 0  digit 2: 1  digit 3: 0  digit 4: 2  \n",
      "Cluster 2 -> digit 0: 3  digit 1: 0  digit 2: 77  digit 3: 25  digit 4: 0  \n",
      "Cluster 3 -> digit 0: 2  digit 1: 36  digit 2: 6  digit 3: 66  digit 4: 6  \n",
      "Cluster 4 -> digit 0: 0  digit 1: 64  digit 2: 1  digit 3: 2  digit 4: 2  \n",
      "Cluster 5 -> digit 0: 6  digit 1: 0  digit 2: 15  digit 3: 7  digit 4: 90  \n"
     ]
    }
   ],
   "source": [
    "actual_cluster_counter = [np.zeros(number_of_groups) for _ in range(number_of_groups)]\n",
    "actual_label = -1\n",
    "for idx in range(len(kmeans_result)):\n",
    "    if idx % 100 == 0:\n",
    "        actual_label += 1\n",
    "    cluster_idx = kmeans_result[idx]\n",
    "    actual_cluster_counter[cluster_idx][actual_label] += 1\n",
    "\n",
    "for cluster_idx in range(len(actual_cluster_counter)):\n",
    "    print('Cluster %d -> ' % (cluster_idx + 1), end='')\n",
    "    for actual_label in range(len(actual_cluster_counter[cluster_idx])):\n",
    "        counter = actual_cluster_counter[cluster_idx][actual_label]\n",
    "        print('digit %d: %d' % (actual_label, counter), end='  ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q02.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 1 -> Recall 0.89  Specificity 0.9925\n",
      "Cluster 2 -> Recall 0.77  Specificity 0.725\n",
      "Cluster 3 -> Recall 0.66  Specificity 0.8325\n",
      "Cluster 4 -> Recall 0.64  Specificity 0.7375\n",
      "Cluster 5 -> Recall 0.9  Specificity 0.93\n"
     ]
    }
   ],
   "source": [
    "def true_negative_per_cluster(cluster_label, actual_cluster_counter):\n",
    "    counter = 0\n",
    "    for i in range(len(actual_cluster_counter)):\n",
    "        for j in range(len(actual_cluster_counter[i])):\n",
    "            if cluster_label != i and cluster_label != j:\n",
    "                counter += actual_cluster_counter[i][j]\n",
    "    return counter\n",
    "\n",
    "actual_positive = 100\n",
    "actual_negative = len(X) - actual_positive\n",
    "cluster_idx = 1\n",
    "for cluster in actual_cluster_counter:\n",
    "    cluster_label = np.argmax(cluster)\n",
    "    recall = cluster[cluster_label] / actual_positive\n",
    "    specificity = true_negative_per_cluster(cluster_label, actual_cluster_counter) / actual_negative\n",
    "\n",
    "    print('Cluster %d -> ' % (cluster_idx), end='')\n",
    "    print('Recall', recall, end='  ')\n",
    "    print('Specificity', specificity)\n",
    "\n",
    "    cluster_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
